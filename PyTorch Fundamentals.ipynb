{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ronald/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.8.2+cpu\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tensores PyTorch\n",
        "Tensores são os tipos de dados fundamentais do PyTorch. Um tensor é uma matriz multidimensional semelhante aos ndarrays de NumPy:\n",
        "\n",
        "* Um escalar pode ser representado como um tensor de dimensão zero.\n",
        "* Um vetor pode ser representado como um tensor unidimensional.\n",
        "* Uma matriz bidimensional pode ser representada como um tensor bidimensional.\n",
        "* Uma matriz multidimensional pode ser representada como um tensor multidimensional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# incializando um tensor\n",
        "x = torch.tensor([[1,2]])\n",
        "y = torch.tensor([[1],[2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensão de x: torch.Size([1, 2])\n",
            "Dimensão de y: torch.Size([2, 1])\n",
            "\n",
            "Tipo de dado de x: torch.int64\n",
            "Tipo de dado de y: <built-in method type of Tensor object at 0x7f94f8ba4ec0>\n"
          ]
        }
      ],
      "source": [
        "# acessando a forma e o tipo do dado;\n",
        "print(f'Dimensão de x: {x.shape}\\nDimensão de y: {y.shape}\\n')\n",
        "print(f'Tipo de dado de x: {x.dtype}\\nTipo de dado de y: {y.type}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Somente booleanos: tensor([False,  True])\n",
            "Diversos tipos de dados: tensor([0., 1., 1., 2.])\n"
          ]
        }
      ],
      "source": [
        "# verificando um tensor do tipo booleano\n",
        "x = torch.tensor([False, True])\n",
        "y = torch.tensor(([False, True, 1, 2.0]))\n",
        "# se tivermos um tensor somente booleano teremos uma saida diferente se a lista conter outros\n",
        "# tipos de dados, os valores serão convertidos em 0 -> False e 1 -> True\n",
        "print(f'Somente booleanos: {x}')\n",
        "print(f'Diversos tipos de dados: {y}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# gerando um tensor de zeros 3 x 4\n",
        "torch.zeros((3,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# gerando um tensor de uns 3 x 4\n",
        "torch.ones((3,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3, 9, 8, 6],\n",
              "        [0, 4, 4, 5],\n",
              "        [3, 1, 9, 3]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# gerando um tensor aleatorio 3 x 4, com valor minimo 0 e maximo 10\n",
        "torch.randint(low=0, high=10, size=(3,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.7923, 0.8356, 0.2059, 0.1652],\n",
              "        [0.4776, 0.8677, 0.5965, 0.0793],\n",
              "        [0.5587, 0.7305, 0.0876, 0.6230]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# gerando numeros aleatorios entre 0 e 1\n",
        "torch.rand(3,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0792,  1.1179,  0.3632,  1.0890],\n",
              "        [-0.4148, -0.5330, -0.7881,  0.8784],\n",
              "        [ 0.2617, -0.4409,  0.3131, -1.6639]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# gerando numeros de uma distribuição normal\n",
        "torch.randn((3,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipo de dado: <class 'numpy.ndarray'>, tipo anterior convertido <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "# convertendo uma matriz Numpy em um tensor\n",
        "import numpy as np\n",
        "x = np.array([[10,20,30],[2,3,4]])\n",
        "y = torch.tensor(x)\n",
        "print(f'Tipo de dado: {type(x)}, tipo anterior convertido {type(y)}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Operações com tensores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor com valores iniciais: tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "Tensor com valores multiplicados por 10: tensor([[10, 20, 30, 40],\n",
            "        [50, 60, 70, 80]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1,2,3,4], [5,6,7,8]])\n",
        "print(f'Tensor com valores iniciais: {x}')\n",
        "print(f'Tensor com valores multiplicados por 10: {x*10}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[11, 12, 13, 14],\n",
              "        [15, 16, 17, 18]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# adicionando valor ao tensor\n",
        "x.add(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eixo cat axis 0:  torch.Size([10, 10, 10]) torch.Size([20, 10, 10])\n",
            "Eixo cat axis 1:  torch.Size([10, 10, 10]) torch.Size([10, 20, 10])\n",
            "Eixo cat axis 2:  torch.Size([10, 10, 10]) torch.Size([10, 10, 20])\n"
          ]
        }
      ],
      "source": [
        "# concatenando tensores\n",
        "x = torch.randn(10,10,10)\n",
        "z = torch.cat([x,x], axis=0)\n",
        "print('Eixo cat axis 0: ', x.shape, z.shape)\n",
        "\n",
        "z = torch.cat([x,x], axis=1)\n",
        "print('Eixo cat axis 1: ', x.shape, z.shape)\n",
        "\n",
        "z = torch.cat([x,x], axis=2)\n",
        "print('Eixo cat axis 2: ', x.shape, z.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [15, 16, 17, 18, 19],\n",
            "        [20, 21, 22, 23, 24]])\n",
            "Maior valor no tensor: 24\n",
            "Menor valor no tensor: 0\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(25).reshape(5,5)\n",
        "print(x)\n",
        "print(f'Maior valor no tensor: {x.max()}')\n",
        "print(f'Menor valor no tensor: {x.min()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([20, 21, 22, 23, 24]),\n",
              "indices=tensor([4, 4, 4, 4, 4]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extraindo os maiores valores do tensor e sua localização/indice (linha da matriz)\n",
        "x.max(dim=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "É importante saber que você pode fazer quase todas as operações do NumPy no PyTorch com quase a mesma sintaxe do NumPy. Operações matemáticas padrão, tais como abs, add, argsort, ceil, floor, sin, cos, tan, cumsum, cumprod, diag, eig, exp, log, log2, log10, mean, median, mode, resize, round, sigmoid, softmax, square, sqrt, svd, e transpose, para citar alguns, pode ser diretamente chamado em qualquer tensor com ou sem eixos onde aplicável. Você sempre pode executar dir(torch.Tensor) para ver todos os métodos possíveis para um tensor de tocha ehelp(torch.Tensor.<method>) para consultar a ajuda e a documentação oficial desse método."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gradientes automáticos de objetos tensores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2., -1.],\n",
            "        [ 1.,  1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# definindo um gradiente e um tensor\n",
        "x = torch.tensor([[2.,-1.],[1.,1.]], requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No código anterior, o requires_grad parâmetro especifica que o gradiente deve ser calculado para o objeto tensor."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Construindo uma rede neural usando PyTorch\n",
        "No capítulo anterior, aprendemos como construir uma rede neural do zero, onde os componentes de uma rede neural são os seguintes:\n",
        "\n",
        "* O número de camadas ocultas\n",
        "* O número de unidades em uma camada oculta\n",
        "* Funções de ativação realizadas nas várias camadas\n",
        "* A função de perda que tentamos otimizar para\n",
        "* A taxa de aprendizagem associada à rede neural\n",
        "* O tamanho do lote de dados aproveitado para construir a rede neural\n",
        "* O número de épocas de propagação para frente e para trás"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "x = torch.rand(1, 6400)\n",
        "y = torch.rand(6400, 5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "x, y = x.to(device), y.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70.6 ms ± 10.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit z=(x@y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "83.2 ms ± 10.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "x, y = x.cpu(), y.cpu()\n",
        "%timeit z=(x@y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111 ms ± 13.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "x = np.random.random((1, 6400))\n",
        "y = np.random.random((6400, 5000))\n",
        "%timeit z = np.matmul(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definindo valores de entrada e saida\n",
        "x = [[1,2],[3,4],[5,6],[7,8]]\n",
        "y = [[3],[7],[11],[15]]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe que na inicialização da variável de entrada e saída anterior, a entrada e a saída são uma lista de listas em que a soma dos valores na lista de entrada são os valores na lista de saída."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# realizando um cast nas entradas\n",
        "X = torch.tensor(x).float()\n",
        "Y = torch.tensor(y).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "X = X.to(device)\n",
        "Y = Y.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definindo a arquitetura da rede neural\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criando uma classe para compor a arquitetura de modelo\n",
        "class MyNeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # chamamos o super para que a classe herde de nn\n",
        "        self.input_to_hidden_layer = nn.Linear(2,8) # camada linear\n",
        "        self.hidden_layer_activation = nn.ReLU() # camada de ativação\n",
        "        self.hidden_to_output_layer = nn.Linear(8,1) # camada linear\n",
        "        # print(nn.Linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=2, out_features=7, bias=True)\n"
          ]
        }
      ],
      "source": [
        "print (nn.Linear ( 2 , 7 ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward (self, x): \n",
        "    x = self.input_to_hidden_layer (x) \n",
        "    x = self.hidden_layer_activation (x) \n",
        "    x = self.hidden_to_output_layer (x) \n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criando uma instancia\n",
        "mynet = MyNeuralNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.4134,  0.5202],\n",
              "        [ 0.2054, -0.1771],\n",
              "        [ 0.6796,  0.3176],\n",
              "        [ 0.1606, -0.1112],\n",
              "        [-0.2189, -0.1808],\n",
              "        [-0.1928, -0.5855],\n",
              "        [ 0.1585,  0.4760],\n",
              "        [-0.0674,  0.4196]], requires_grad=True)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mynet.input_to_hidden_layer.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7fbcadc844a0>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Todos os parâmetros de uma rede neural podem ser obtidos usando o seguinte código:\n",
        "mynet.parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.4134,  0.5202],\n",
            "        [ 0.2054, -0.1771],\n",
            "        [ 0.6796,  0.3176],\n",
            "        [ 0.1606, -0.1112],\n",
            "        [-0.2189, -0.1808],\n",
            "        [-0.1928, -0.5855],\n",
            "        [ 0.1585,  0.4760],\n",
            "        [-0.0674,  0.4196]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.5410,  0.2738,  0.0173,  0.3724,  0.6316, -0.5195,  0.6922,  0.0688],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1079,  0.3123, -0.1086, -0.0346, -0.0574, -0.1802, -0.1518, -0.0411]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0404], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for i in mynet.parameters():\n",
        "    print(i)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conjunto de dados, DataLoader e tamanho do lote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = [[1 , 2], [3 , 4], [5 , 6], [7 , 8]] \n",
        "y = [[ 3 ], [ 7 ], [ 11 ], [ 15 ]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = torch.tensor (x).float () \n",
        "Y = torch.tensor (y).float ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available () else 'cpu'\n",
        "X = X.to(device) \n",
        "Y = Y.to(device)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# instanciando uma classe dataset\n",
        "class Mydataset(Dataset):\n",
        "    \"\"\"Definindo metodo que pega pares de entrada e saida\n",
        "    e converte em objetos flutuantes\"\"\"\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x).float()\n",
        "        self.y = torch.tensor(y).float()\n",
        "\n",
        "    \"\"\"Especifica o comprimento do conjunto de entrada de dados\"\"\"\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    \"\"\"Método usado para buscar uma linha específica\"\"\"\n",
        "    def __getitem__(self, ix):\n",
        "        return self.x[ix], self.y[ix]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15532/3859479177.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.x = torch.tensor(x).float()\n",
            "/tmp/ipykernel_15532/3859479177.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.y = torch.tensor(y).float()\n"
          ]
        }
      ],
      "source": [
        "# criando uma instancia\n",
        "ds = Mydataset(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "dl = DataLoader(ds, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [5., 6.]]) tensor([[ 3.],\n",
            "        [11.]])\n",
            "tensor([[7., 8.],\n",
            "        [3., 4.]]) tensor([[15.],\n",
            "        [ 7.]])\n"
          ]
        }
      ],
      "source": [
        "# abaixo um codigo ilustrativo para impressao de lotes de entrada e saida de dados\n",
        "for x, y in dl:\n",
        "    print(x, y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe que o código anterior resultou em dois conjuntos de pares de entrada-saída, pois havia um total de quatro pontos de dados no conjunto de dados original, enquanto o tamanho do lote especificado era 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definindo uma classe de rede\n",
        "class MyNeuralNet (nn.Module): \n",
        "    def __init__(self): \n",
        "        super().__init__() \n",
        "        self.input_to_hidden_layer = nn.Linear (2,8) \n",
        "        self.hidden_layer_activation = nn.ReLU () \n",
        "        self.hidden_to_output_layer = nn.Linear (8,1) \n",
        "    def forward (self, x): \n",
        "        x = self.input_to_hidden_layer (x) \n",
        "        x = self.hidden_layer_activation (x) \n",
        "        x = self.hidden_to_output_layer (x) \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definindo o modelo do objeto\n",
        "mynet = MyNeuralNet().to(device)\n",
        "loss_func = nn.MSELoss()\n",
        "from torch.optim import SGD\n",
        "opt = SGD(mynet.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.30396437644958496\n"
          ]
        }
      ],
      "source": [
        "# loop pelos lotes de pontos de dados para minimizar o valor de perda\n",
        "import time\n",
        "loss_history = []\n",
        "start = time.time()\n",
        "for _ in range(50):\n",
        "    for data in dl:\n",
        "        x, y = data\n",
        "        opt.zero_grad()\n",
        "        loss_value = loss_func(mynet(x), y)\n",
        "        loss_value.backward()\n",
        "        opt.step()\n",
        "        loss_history.append(loss_value)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Previsão de novos pontos de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criando novo ponto de dados para teste de modelo\n",
        "val_x = [[10,11]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# realizando um cast nos pontos de dados\n",
        "val_x = torch.tensor(val_x).float().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[20.4487]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# passando o objeto tensor pela rede neural treinada\n",
        "mynet(val_x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementando uma função de perda personalizada\n",
        "Em certos casos, podemos ter que implementar uma função de perda customizada para o problema que estamos resolvendo - especialmente em casos de uso complexos envolvendo detecção de objetos / redes adversas geradoras ( GANs ). O PyTorch fornece as funcionalidades para construirmos uma função de perda personalizada, escrevendo uma função nossa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "x = [[1,2],[3,4],[5,6],[7,8]]\n",
        "y = [[3],[7],[11],[15]]\n",
        "\n",
        "X = torch.tensor(x).float()\n",
        "Y = torch.tensor(y).float()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "X = X.to(device)\n",
        "Y = Y.to(device) \n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self,x,y):\n",
        "        self.x = torch.tensor(x).float()\n",
        "        self.y = torch.tensor(y).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        return self.x[ix], self.y[ix]\n",
        "\n",
        "class MyNeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_to_hidden_layer = nn.Linear(2,8)\n",
        "        self.hidden_layer_activation = nn.ReLU()\n",
        "        self.hidden_to_output_layer = nn.Linear(8,1)\n",
        "\n",
        "    def foward(self, x):\n",
        "        x = self.input_to_hidden_layer(x)\n",
        "        x = self.hidden_layer_activation(x)\n",
        "        x = self.hidden_to_output_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15532/40928522.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.x = torch.tensor(x).float()\n",
            "/tmp/ipykernel_15532/40928522.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.y = torch.tensor(y).float()\n"
          ]
        }
      ],
      "source": [
        "ds = MyDataset(X, Y)\n",
        "dl = DataLoader(ds, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "mynet = MyNeuralNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_mean_squared_error(_y, y):\n",
        "    loss = (_y-y)**2\n",
        "    loss = loss.mean()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_func \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m----> 2\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss_func(\u001b[43mmynet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m,Y)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_value)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:201\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss_func = nn.MSELoss()\n",
        "loss_value = loss_func(mynet(X),Y)\n",
        "print(loss_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m my_mean_squared_error(\u001b[43mmynet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m,Y)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:201\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "my_mean_squared_error(mynet(X),Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0000, 0.0000, 0.4896, 0.4493, 0.0000, 0.0980, 0.4159, 0.0000],\n",
            "        [0.0908, 0.1018, 0.3949, 2.0867, 0.0000, 0.0000, 0.5881, 0.0000],\n",
            "        [0.2633, 0.2914, 0.3002, 3.7241, 0.0000, 0.0000, 0.7604, 0.0000],\n",
            "        [0.4358, 0.4809, 0.2055, 5.3614, 0.0000, 0.0000, 0.9326, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input_to_hidden = mynet.input_to_hidden_layer(X) \n",
        "hidden_activation = mynet.hidden_layer_activation (input_to_hidden) \n",
        "print(hidden_activation)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe que tivemos que chamar a input_to_hidden_layerativação antes de chamar, hidden_layer_activationpois a saída de input_to_hidden_layeré a entrada para a hidden_layer_activationcamada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Neuralnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_to_hidden_layer = nn.Linear(2,8)\n",
        "        self.hidden_layer_activation = nn.ReLU()\n",
        "        self.hidden_to_output_layer = nn.Linear(8,1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden1 = self.input_to_hidden_layer(x)\n",
        "        hidden2 = self.hidden_layer_activation(hidden1)\n",
        "        output = self.hidden_to_output_layer(hidden2)\n",
        "        return output, hidden2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Usando um método sequencial para construir uma rede neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = [[ 1 , 2 ], [ 3 , 4 ], [ 5 , 6 ], [ 7 , 8 ]] \n",
        "y = [[ 3 ], [ 7 ], [ 11 ], [ 15 ]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x).float().to(device)\n",
        "        self.y = torch.tensor(y).float().to(device)\n",
        "    def __getitem__(self, ix):\n",
        "        return self.x[ix], self.y[ix]\n",
        "    def __len__(self): \n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = MyDataset(x, y)\n",
        "dl = DataLoader(ds, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = nn.Sequential(nn.Linear(2, 8), nn.ReLU(), nn.Linear(8, 1)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        }
      ],
      "source": [
        "# instalando o package torch_summary\n",
        "!pip install torch_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─Linear: 1-1                            [-1, 8]                   24\n",
            "├─ReLU: 1-2                              [-1, 8]                   --\n",
            "├─Linear: 1-3                            [-1, 1]                   9\n",
            "==========================================================================================\n",
            "Total params: 33\n",
            "Trainable params: 33\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.00\n",
            "==========================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.00\n",
            "==========================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Linear: 1-1                            [-1, 8]                   24\n",
              "├─ReLU: 1-2                              [-1, 8]                   --\n",
              "├─Linear: 1-3                            [-1, 1]                   9\n",
              "==========================================================================================\n",
              "Total params: 33\n",
              "Trainable params: 33\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, torch.zeros(1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6173429489135742\n"
          ]
        }
      ],
      "source": [
        "\"\"\"A seguir, definimos a função de perda ( loss_func) e o \n",
        "otimizador ( opt) e treinamos o modelo\"\"\"\n",
        "\n",
        "loss_func = nn.MSELoss()\n",
        "from torch.optim import SGD\n",
        "opt = SGD(model.parameters(), lr = 0.001)\n",
        "import time\n",
        "loss_history = []\n",
        "start = time.time()\n",
        "for _ in range(50):\n",
        "    for ix, iy in dl:\n",
        "        opt.zero_grad()\n",
        "        loss_value = loss_func(model(ix),iy)\n",
        "        loss_value.backward()\n",
        "        opt.step()\n",
        "        loss_history.append(loss_value)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# agora que o modelo está treinado podemos prever os valores\n",
        "val = [[8 , 9], [10 ,11], [1.5, 2.5]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[16.5386],\n",
              "        [20.2211],\n",
              "        [ 4.5418]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(torch.tensor(val).float().to(device))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe que a saída do código anterior, conforme mostrado no comentário, está próxima do esperado (que é a soma dos valores de entrada)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# salvando\n",
        "torch.save(model.to('cpu').state_dict(), 'mymodel.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lendo o arquivo\n",
        "state_dict = torch.load ('mymodel.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict (state_dict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se todos os nomes de peso estiverem presentes no modelo, você receberá uma mensagem dizendo que todas as chaves foram combinadas. Isso significa que podemos carregar nosso modelo do disco, para todos os fins, em qualquer máquina do mundo."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Attention\n",
        "Every codes here are book's Moder Computer vision with PyTorch<br>\n",
        "https://learning.oreilly.com/library/view/modern-computer-vision/9781839213472/f1d61b2c-dbb8-43ac-ac4e-75941daecc4c.xhtml#uuid-7b6ca1ba-20ea-4326-a10f-61c46baa7103 "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
