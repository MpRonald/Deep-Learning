{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_Introduction_Tensors.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IqPFmxxvm18OgRxdY2gi8u1DdYmrJyJJ",
      "authorship_tag": "ABX9TyNv8rLfbZiMQt8EPwkCka+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MpRonald/Deep-Learning/blob/main/Deep_Learning_Introduction_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Introduction"
      ],
      "metadata": {
        "id": "sdcsRzegqan_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SuhD0kDkab8",
        "outputId": "f1ad6be3-d10e-4d87-abef-757ea71e1266"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBdWPR2XajV5",
        "outputId": "7d105f3e-9b0f-49d6-9854-ea3ade70cc58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# loading dataset MNIST\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dACaSbDuazyg",
        "outputId": "c0e53a37-fe9f-4e97-ef5f-0a8da4410203"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FNYq_cUbEcU",
        "outputId": "19b7c8b4-fe6e-4472-8fc1-889018f59f74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
              "        224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
              "        252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
              "        253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
              "        179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
              "         84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
              "         28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
              "          0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
              "          0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
              "        178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
              "        252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
              "        233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
              "         37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc5lryvSbH2C",
        "outputId": "ba326716-4620-4a4b-95a0-b40dbff147da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu4yzuNObL_6",
        "outputId": "245ab0db-f784-457f-c23a-10c89ebd4754"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 116, 125, 171,\n",
              "        255, 255, 150,  93,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253,\n",
              "        253, 253, 253, 218,  30,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253, 213,\n",
              "        142, 176, 253, 253, 122,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  52, 250, 253, 210,  32,  12,\n",
              "          0,   6, 206, 253, 140,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  77, 251, 210,  25,   0,   0,\n",
              "          0, 122, 248, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  31,  18,   0,   0,   0,\n",
              "          0, 209, 253, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        117, 247, 253, 198,  10,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76,\n",
              "        247, 253, 231,  63,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128,\n",
              "        253, 253, 144,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 176, 246,\n",
              "        253, 159,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 234, 253,\n",
              "        233,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 198, 253, 253,\n",
              "        141,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  78, 248, 253, 189,\n",
              "         12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  19, 200, 253, 253, 141,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 134, 253, 253, 173,  12,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  25,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  43,  20,\n",
              "         20,  20,  20,   5,   0,   5,  20,  20,  37, 150, 150, 150, 147,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253, 253, 253,\n",
              "        253, 253, 253, 168, 143, 166, 253, 253, 253, 253, 253, 253, 253,\n",
              "        123,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 174, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 253, 253, 253, 249, 247, 247, 169, 117, 117,\n",
              "         57,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 118, 123, 123, 123,\n",
              "        166, 253, 253, 253, 155, 123, 123,  41,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The workflow will be as follows: First, we’ll feed the neural network the training data, train_images and train_labels. The network will then learn to associate images and labels. Finally, we’ll ask the network to produce predictions for test_images, and we’ll verify whether these predictions match the labels from test_labels."
      ],
      "metadata": {
        "id": "88hs4qhSbY_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build a network\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential([layers.Dense(512, activation=\"relu\"),\n",
        "                          layers.Dense(10, activation=\"softmax\")])"
      ],
      "metadata": {
        "id": "rP1lBh4FbPCH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here, our model consists of a sequence of two Dense layers, which are densely connected (also called fully connected) neural layers. The second (and last) layer is a 10-way softmax classification layer, which means it will return an array of 10 probability scores (summing to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes.\n",
        "\n",
        "* An optimizer—The mechanism through which the model will update itself based on the training data it sees, so as to improve its performance.\n",
        "\n",
        "* A loss function—How the model will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
        "\n",
        "* Metrics to monitor during training and testing—Here, we’ll only care about accuracy (the fraction of the images that were correctly classified)."
      ],
      "metadata": {
        "id": "XEvC7ngzcCRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The compilation step\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "6Inry9sSbkTY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before training, we’ll preprocess the data by reshaping it into the shape the model expects and scaling it so that all values are in the [0, 1] interval. Previously, our training images were stored in an array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval. We’ll transform it into a float32 array of shape (60000, 28 * 28) with values between 0 and 1."
      ],
      "metadata": {
        "id": "Aq5TGiqMcpa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the image data\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255 \n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "yZGXT2_wcYHX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "278TGyZ6cttE",
        "outputId": "7354cb93-9cff-4156-df5c-c9b8f4931656"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 8s 13ms/step - loss: 0.2565 - accuracy: 0.9262\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.1029 - accuracy: 0.9695\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0675 - accuracy: 0.9798\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0488 - accuracy: 0.9851\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.0361 - accuracy: 0.9895\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7381c66d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the model to make predictions\n",
        "test_digits = test_images[0:10]\n",
        "predictions = model.predict(test_digits)\n",
        "predictions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtALj1oDc2-l",
        "outputId": "fa77ba84-a568-4da7-e0b6-a747133e0143"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.6519238e-08, 6.7339601e-10, 1.1894500e-05, 1.2698821e-04,\n",
              "       1.0474646e-11, 4.0482004e-08, 3.0953870e-14, 9.9985802e-01,\n",
              "       4.8758329e-07, 2.5651684e-06], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Each number of index i in that array corresponds to the probability that digit image test_digits[0] belongs to class i.\n",
        "\n",
        "This first test digit has the highest probability score (0.99999106, almost 1) at index 7, so according to our model, it must be a 7:"
      ],
      "metadata": {
        "id": "o54VdvSSdpco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0].argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE3I6g_kdjh1",
        "outputId": "42a64e1f-6083-4324-d459-cc1146a60c83"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0][7] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2AEQ_tCdwtK",
        "outputId": "ead8c29a-e54a-443e-914d-83f6318aa6d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.999858"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TTCT2g_dxvR",
        "outputId": "635a8b57-49c4-4d7e-d548-dbb04b88cfdc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[2].argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jCL1JFed0L2",
        "outputId": "c6efe9ac-2d66-4bdd-eb5c-bf4f055c78cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0][7] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u67nZQfWd2Za",
        "outputId": "ce132fd8-ad56-4ae8-c11e-a206ffbba33d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.999858"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8X8Gi3Xd4cO",
        "outputId": "0153be61-831e-4e28-9f41-eaa7ce55638b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on new data\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYc9LJfvd-0C",
        "outputId": "ca586d15-4d31-4b73-cffd-0808f8499c11"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9809\n",
            "test_acc: 0.98089998960495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The test-set accuracy turns out to be 97.8%—that’s quite a bit lower than the training-set accuracy (98.9%). "
      ],
      "metadata": {
        "id": "YMAefUucfIFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimensions\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images.ndim "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eee6AzYe4E9",
        "outputId": "3ba5e038-c729-4172-f8c5-03d7c3cf54d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uesiMdFrn-0U",
        "outputId": "12acf38f-23b4-4346-f75c-9029a9bf964f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### So what we have here is a rank-3 tensor of 8-bit integers. More precisely, it’s an array of 60,000 matrices of 28 × 28 integers. Each such matrix is a grayscale image, with coefficients between 0 and 255."
      ],
      "metadata": {
        "id": "LbKZb4ScpfXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the fourth digit\n",
        "import matplotlib.pyplot as plt\n",
        "digit = train_images[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JPI113_bpZ3_",
        "outputId": "84b92a94-b557-43dc-cf1c-e660598316c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naturally, the corresponding label is the integer 9:\n",
        "train_labels[4] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfHtl7OnpmGh",
        "outputId": "89cf8bfb-bc17-4243-f2f7-18098a4d2a62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit = train_images[15]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "MjyzGOiXp4bG",
        "outputId": "a682f864-4679-458f-a761-b7b29194927b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANnElEQVR4nO3db4xV9Z3H8c9Hl/rANhFlgsSi062IEpPSZoKbQKobs8Q/D7AxMcXYsMYwPBClSR+sYU0wPDJGQEw2NXQlpVCtmJaICbooaSR9YOOgrCC4lSUogyMM0ViQB6zw3QdzaKY499zhnvtv+L5fyeTee773nvPN0Q/n3vO75/4cEQJw8buk0w0AaA/CDiRB2IEkCDuQBGEHkviHdm5sypQp0dvb285NAqkcOnRIx48f91i1SmG3fYektZIulfSfEfFk2fN7e3s1MDBQZZMASvT19dWsNfw23valkv5D0p2SZklaaHtWo+sD0FpVPrPPkXQgIg5GxGlJv5O0oDltAWi2KmG/RtLhUY8Hi2V/x3a/7QHbA8PDwxU2B6CKlp+Nj4h1EdEXEX09PT2t3hyAGqqE/Yik6aMef7dYBqALVQn7O5Jm2P6e7W9J+qmkrc1pC0CzNTz0FhFf214q6b80MvS2PiI+aFpnAJqq0jh7RGyTtK1JvQBoIb4uCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii0pTNtg9JOiHpjKSvI6KvGU0BaL5KYS/8c0Qcb8J6ALQQb+OBJKqGPSRtt73Ldv9YT7Ddb3vA9sDw8HDFzQFoVNWwz4uIH0m6U9LDtn98/hMiYl1E9EVEX09PT8XNAWhUpbBHxJHi9pikLZLmNKMpAM3XcNhtX277O+fuS5ovaW+zGgPQXFXOxk+VtMX2ufW8EBGvN6UrAE3XcNgj4qCkHzSxFwAtxNAbkARhB5Ig7EAShB1IgrADSTTjQhgktmrVqtL66dOna9b2799f+tpNmzY11NM5N954Y83avn37Kq17IuLIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM5+kXvrrbdK63v27Cmt79y5s7S+ZcuW0vrZs2dL62WKy6cbduDAgZq1m266qfS19b4DMBFxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnb4OhoaHS+sKFC0vrBw8ebHjbX375ZWn95MmTpfWIKK339ZVP3Ltr167SeiudOXOmZu3UqVNt7KQ7cGQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ2+CN998s7S+ePHi0vonn3zSzHaaqt513VOmTCmtHz9+vGbt008/LX3tgw8+WFo/fPhwab3MrFmzGn7tRFX3yG57ve1jtveOWnal7Tdsf1TcTm5tmwCqGs/b+F9LuuO8ZY9J2hERMyTtKB4D6GJ1wx4ROyV9ft7iBZI2FPc3SLqnyX0BaLJGT9BNjYhzX/j+TNLUWk+03W97wPbA8PBwg5sDUFXls/ExcqVEzaslImJdRPRFRF9PT0/VzQFoUKNhP2p7miQVt8ea1xKAVmg07FslLSruL5L0SnPaAdAqdcfZbb8o6TZJU2wPSloh6UlJm20/JOljSfe1sslu99RTT5XWWz2Oftlll9Ws1evtlltuKa3PnDmzoZ7Oueqqq2rW1q5dW/raKuPoktTb21uztnHjxkrrnojqhj0iav2ywu1N7gVAC/F1WSAJwg4kQdiBJAg7kARhB5LgEtdx2r59e83a22+/3dJtX3vttaX1smGkefPmNbudphkcHGzp+hcsWFCzVu/S3IsRR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9nFatWpVzdpXX31Vad1z584tra9YsaK03smx9C+++KK0/tprr9Ws7dy5s9K26+23u+++u9L6LzYc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZx6m/v79mrd60VldccUVp/YUXXiitX3311aX1TnruuedK648//njD67755ptL65s3by6td/N+6wSO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPs43Tvvfc2VJvoXn311dL6ypUrG173pEmTSutLliwprTOOfmHqHtltr7d9zPbeUcuesH3E9u7i767WtgmgqvG8jf+1pDvGWL4mImYXf9ua2xaAZqsb9ojYKenzNvQCoIWqnKBbavv94m3+5FpPst1ve8D2QL3vkANonUbD/ktJ35c0W9KQpJq/xhgR6yKiLyL6enp6GtwcgKoaCntEHI2IMxFxVtKvJM1pblsAmq2hsNueNurhTyTtrfVcAN2h7ji77Rcl3SZpiu1BSSsk3WZ7tqSQdEhS+YAoJqyyOc4lyXbD63722WdL62W/IYALVzfsEbFwjMXPt6AXAC3E12WBJAg7kARhB5Ig7EAShB1Igktck1u+fHlpPSJatu1bb721ZevGN3FkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGe/yJ0+fbq0/t5775XW613CWq++du3amrUZM2aUvhbNxZEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnP0icOrUqZq1TZs2lb52+/btlbZ9//33l9YfeOCBmrVLLuFY007sbSAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2CeDEiROl9cWLF9esvfzyy5W2/cwzz5TWly5dWlpnLL171P0vYXu67T/a3mf7A9vLiuVX2n7D9kfF7eTWtwugUeP5Z/drSb+IiFmS/knSw7ZnSXpM0o6ImCFpR/EYQJeqG/aIGIqId4v7JyTtl3SNpAWSNhRP2yDpnlY1CaC6C/pAZbtX0g8l/VnS1IgYKkqfSZpa4zX9tgdsDwwPD1doFUAV4w677W9L+r2kn0fEX0fXYmT2vzFnAIyIdRHRFxF9PT09lZoF0Lhxhd32JI0E/bcR8Ydi8VHb04r6NEnHWtMigGaoO/Tmkd8Kfl7S/ohYPaq0VdIiSU8Wt6+0pENocHCwtF5leO36668vrT/66KMNrxvdZTzj7HMl/UzSHtu7i2XLNRLyzbYfkvSxpPta0yKAZqgb9oj4k6RaMwHc3tx2ALQKX28CkiDsQBKEHUiCsANJEHYgCS5x7QIffvhhaX316tWl9TI33HBDaf31119veN2YWDiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLN3gZUrV5bWX3rppYbX/cgjj5TWr7vuuobXjYmFIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4exvs3bu3tF5vSuZ6lixZUrN2++38ADBGcGQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTGMz/7dEm/kTRVUkhaFxFrbT8habGk4eKpyyNiW6sancg2btxYWt+2rXy31bvmfNmyZTVrM2fOLH0t8hjPl2q+lvSLiHjX9nck7bL9RlFbExFPt649AM0ynvnZhyQNFfdP2N4v6ZpWNwaguS7oM7vtXkk/lPTnYtFS2+/bXm97co3X9NsesD0wPDw81lMAtMG4w27725J+L+nnEfFXSb+U9H1JszVy5F811usiYl1E9EVEX09PTxNaBtCIcYXd9iSNBP23EfEHSYqIoxFxJiLOSvqVpDmtaxNAVXXDbtuSnpe0PyJWj1o+bdTTfiKp/NIuAB01nrPxcyX9TNIe27uLZcslLbQ9WyPDcYck1b7OMrn58+eX1p9+unxAY82aNaV1htcwHuM5G/8nSR6jxJg6MIHwDTogCcIOJEHYgSQIO5AEYQeSIOxAEvyUdBvU+znnM2fOtKkTZMaRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeScES0b2P2sKSPRy2aIul42xq4MN3aW7f2JdFbo5rZ23URMebvv7U17N/YuD0QEX0da6BEt/bWrX1J9NaodvXG23ggCcIOJNHpsK/r8PbLdGtv3dqXRG+NaktvHf3MDqB9On1kB9AmhB1IoiNht32H7f+xfcD2Y53ooRbbh2zvsb3b9kCHe1lv+5jtvaOWXWn7DdsfFbdjzrHXod6esH2k2He7bd/Vod6m2/6j7X22P7C9rFje0X1X0ldb9lvbP7PbvlTSXyT9i6RBSe9IWhgR+9raSA22D0nqi4iOfwHD9o8lnZT0m4i4uVj2lKTPI+LJ4h/KyRHxb13S2xOSTnZ6Gu9itqJpo6cZl3SPpH9VB/ddSV/3qQ37rRNH9jmSDkTEwYg4Lel3khZ0oI+uFxE7JX1+3uIFkjYU9zdo5H+WtqvRW1eIiKGIeLe4f0LSuWnGO7rvSvpqi06E/RpJh0c9HlR3zfcekrbb3mW7v9PNjGFqRAwV9z+TNLWTzYyh7jTe7XTeNONds+8amf68Kk7QfdO8iPiRpDslPVy8Xe1KMfIZrJvGTsc1jXe7jDHN+N90ct81Ov15VZ0I+xFJ00c9/m6xrCtExJHi9pikLeq+qaiPnptBt7g91uF+/qabpvEea5pxdcG+6+T0550I+zuSZtj+nu1vSfqppK0d6OMbbF9enDiR7cslzVf3TUW9VdKi4v4iSa90sJe/0y3TeNeaZlwd3ncdn/48Itr+J+kujZyR/19J/96JHmr09Y+S/rv4+6DTvUl6USNv6/5PI+c2HpJ0laQdkj6S9KakK7uot42S9kh6XyPBmtah3uZp5C36+5J2F393dXrflfTVlv3G12WBJDhBByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D/2QR8zRYramAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "516trJISp9bI",
        "outputId": "7a67c68a-8b9f-4f54-af60-8edb611713c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulating tensors in NumPy"
      ],
      "metadata": {
        "id": "xVMw0SitqYfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The following example selects digits \n",
        "#10 to #100 (#100 isn’t included) and puts them in an array of shape (90, 28, 28):\n",
        "my_slice = train_images[10:100]\n",
        "my_slice.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmMUatB4qAVx",
        "outputId": "037567ee-612f-44b7-c96a-4b3665e15918"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### It’s equivalent to this more detailed notation, which specifies a start index and stop index for the slice along each tensor axis. Note that : is equivalent to selecting the entire axis:"
      ],
      "metadata": {
        "id": "zRcqsly1q0Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_slice = train_images[10:100, :, :] # the same this example [10:100, 0:28, 0:28]\n",
        "my_slice.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02lhBZmZqtSP",
        "outputId": "9d0528e0-8c98-4956-8515-feec2e4d1da1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_slice = train_images[10:100, 0:28, 0:28]\n",
        "my_slice.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIX6dHsVq7Qj",
        "outputId": "63f5ea9f-41fe-4c80-914b-025eb38f9c7e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In general, you may select slices between any two indices along each tensor axis. For instance, in order to select 14 × 14 pixels in the bottom-right corner of all images, you would do this:"
      ],
      "metadata": {
        "id": "InqGwfAcrTWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_slice = train_images[:, 14:, 14:]\n",
        "my_slice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTc6DI4eq-fX",
        "outputId": "ea700fb6-5b0e-4e6a-af4a-2fa13742110f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[240, 253, 253, ...,   0,   0,   0],\n",
              "        [ 45, 186, 253, ...,   0,   0,   0],\n",
              "        [  0,  16,  93, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0]],\n",
              "\n",
              "       [[241, 243, 234, ...,   0,   0,   0],\n",
              "        [143,  91,  28, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[253, 254, 253, ...,   0,   0,   0],\n",
              "        [ 72, 192, 254, ...,   0,   0,   0],\n",
              "        [  0,   6, 242, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0]],\n",
              "\n",
              "       [[  0,  31, 127, ...,   0,   0,   0],\n",
              "        [ 27, 218, 252, ...,   0,   0,   0],\n",
              "        [194, 253, 217, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0]],\n",
              "\n",
              "       [[ 97, 254, 252, ...,   0,   0,   0],\n",
              "        [232, 181,  60, ...,   0,   0,   0],\n",
              "        [ 46,   0,   0, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_slice = train_images[:, 7:-7, 7:-7]\n",
        "my_slice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zS6VfOXrXem",
        "outputId": "c7b59987-96b7-43b7-d0a5-e3140873dd09"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 49, 238, 253, ...,  93,  82,  82],\n",
              "        [ 18, 219, 253, ...,   0,   0,   0],\n",
              "        [  0,  80, 156, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0, ..., 253, 207,   2],\n",
              "        [  0,   0,   0, ..., 250, 182,   0],\n",
              "        [  0,   0,   0, ...,  78,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0, ...,  84, 252, 253],\n",
              "        [  0,   0,   0, ...,  96, 189, 253],\n",
              "        [  0,   0,   0, ...,  47,  79, 255],\n",
              "        ...,\n",
              "        [252, 145,   0, ..., 252, 173,   0],\n",
              "        [253, 225,   0, ..., 162,   0,   0],\n",
              "        [252, 249, 146, ...,  56,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0, ...,   0,   2, 153],\n",
              "        [  0,   0,   0, ...,   0,  27, 254],\n",
              "        [  0,   0,   0, ...,   0, 183, 254],\n",
              "        ...,\n",
              "        [  0,   0,   0, ..., 254,  57,   0],\n",
              "        [  0,   0,   0, ..., 254,  57,   0],\n",
              "        [  0,   0,   0, ..., 255,  94,   0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[  0,   0,   0, ..., 223, 159, 131],\n",
              "        [  0,   0,   0, ...,  27,   0,   0],\n",
              "        [  0,   0,  54, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0, ..., 173,   0,   0],\n",
              "        [  0,   0,   0, ..., 173,   0,   0],\n",
              "        [  0,   0,   0, ...,  74,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        [  0,   0,   0, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [247, 110,   0, ..., 146, 163,  63],\n",
              "        [236, 128,   0, ..., 178,  12,   0],\n",
              "        [239, 196, 169, ...,   0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0, ..., 254, 212,  27],\n",
              "        [  0,   0,   0, ..., 218, 237, 248],\n",
              "        [  0,   0,   0, ...,   0,  92, 231],\n",
              "        ...,\n",
              "        [  0, 110, 254, ...,   0,   0,   0],\n",
              "        [131, 254, 154, ...,   0,   0,   0],\n",
              "        [209, 153,  19, ...,   0,   0,   0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The notion of data batches"
      ],
      "metadata": {
        "id": "rMlZ3514riLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In addition, deep learning models don’t process an entire dataset at once; rather, they break the data into small batches. Concretely, here’s one batch of our MNIST digits, with a batch size of 128:\n",
        "\n"
      ],
      "metadata": {
        "id": "Jp5s0ANvr0dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = train_images[:128]\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGwTsvDereLj",
        "outputId": "5a90592e-51eb-40d9-ca9b-2cfa0031013b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And here’s the next batch:\n",
        "batch = train_images[128:256]\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR0aSCE1r21q",
        "outputId": "529b0cd5-7414-4637-f07f-0ac36012adf7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And the nth batch:\n",
        "n = 3 \n",
        "batch = train_images[128 * n:128 * (n + 1)]\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7Vf-kzor58H",
        "outputId": "950b9b91-b55a-4b02-8c92-e8e268277064"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The gears of neural networks: Tensor operations\n",
        "### Much as any computer program can be ultimately reduced to a small set of binary operations on binary inputs (AND, OR, NOR, and so on), all transformations learned by deep neural networks can be reduced to a handful of tensor operations (or tensor functions) applied to tensors of numeric data. For instance, it’s possible to add tensors, multiply tensors, and so on.\n",
        "\n",
        "### In our initial example, we built our model by stacking Dense layers on top of each other. A Keras layer instance looks like this:"
      ],
      "metadata": {
        "id": "_X6fyDFyunSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.Dense(512, activation=\"relu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGLVfIWJr-Bb",
        "outputId": "454e226b-7636-4f28-e6b7-d4a18412904f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7ff733960fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This layer can be interpreted as a function, which takes as input a matrix and returns another matrix—a new representation for the input tensor. Specifically, the function is as follows (where W is a matrix and b is a vector, both attributes of the layer):"
      ],
      "metadata": {
        "id": "ikgQt3Hyu8d1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The \"relu\" operation and addition are element-wise operations: operations that are applied independently to each entry in the tensors being considered. This means these operations are highly amenable to massively parallel implementations (vectorized implementations, a term that comes from the vector processor supercomputer architecture from the 1970–90 period). If you want to write a naive Python implementation of an element-wise operation, you use a for loop, as in this naive implementation of an element-wise relu operation:"
      ],
      "metadata": {
        "id": "m9kvfcbtvIMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_relu(x):\n",
        "    assert len(x.shape) == 2 # x is a rank-2 NumPy tensor.      \n",
        "    x = x.copy() # Avoid overwriting the input tensor.                  \n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] = max(x[i, j], 0)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ytvC0V0JuzDv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2       \n",
        "    assert x.shape == y.shape\n",
        "    x = x.copy()                   \n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ],
      "metadata": {
        "id": "0WxNziTjwSuP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s actually time the difference:\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "  \n",
        "t0 = time.time() \n",
        "for _ in range(1000):\n",
        "    z = x + y\n",
        "    z = np.maximum(z, 0.) \n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54oz1tGQvAl7",
        "outputId": "b1762e21-2eb2-476c-c61a-42d738cd72e9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took: 0.01 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time() \n",
        "for _ in range(1000):\n",
        "    z = naive_add(x, y)\n",
        "    z = naive_relu(z) \n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKYXPaGAwKeH",
        "outputId": "953b7c25-a79b-4b85-a9f1-2312e9b00559"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took: 4.30 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In terms of implementation, no new rank-2 tensor is created, because that would be terribly inefficient. The repetition operation is entirely virtual: it happens at the algorithmic level rather than at the memory level. But thinking of the vector being repeated 10 times alongside a new axis is a helpful mental model. Here’s what a naive implementation would look like:"
      ],
      "metadata": {
        "id": "-qK5g0VUxaSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_add_matrix_and_vector(x, y):\n",
        "    assert len(x.shape) == 2 # x is a rank-2 NumPy tensor.\n",
        "    assert len(y.shape) == 1 # y is a NumPy vector.\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    x = x.copy() # Avoid overwriting the input tensor.\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[j]\n",
        "    return x"
      ],
      "metadata": {
        "id": "9RqhlxhEwQvZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor product\n",
        "### The tensor product, or dot product (not to be confused with an element-wise product, the * operator), is one of the most common, most useful tensor operations.\n",
        "\n",
        "### In NumPy, a tensor product is done using the np.dot function (because the mathematical notation for tensor product is usually a dot):"
      ],
      "metadata": {
        "id": "irHh9DmSx7j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.random((32,))\n",
        "y = np.random.random((32,))\n",
        "z = np.dot(x, y)"
      ],
      "metadata": {
        "id": "PZTC_vQtxmVz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv6NKXy1yFrp",
        "outputId": "477963c9-b639-48f1-b27a-8a0135b29a0b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.887144913697249"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x * y"
      ],
      "metadata": {
        "id": "X5bhvEd8yGaE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mathematically, what does the dot operation do? Let’s start with the dot \n",
        "# product of two vectors, x and y. It’s computed as follows:\n",
        "\n",
        "def naive_vector_dot(x, y):\n",
        "    assert len(x.shape) == 1 # x and y are NumPy vectors.\n",
        "    assert len(y.shape) == 1 # x and y are NumPy vectors.\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    z = 0. \n",
        "    for i in range(x.shape[0]):\n",
        "        z += x[i] * y[i]\n",
        "    return z"
      ],
      "metadata": {
        "id": "SiTdkoBNyJd_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You can also take the dot product between a matrix x and a vector y, which returns a vector where the coefficients are the dot products between y and the rows of x. You implement it as follows:"
      ],
      "metadata": {
        "id": "wDgydJMDy3xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_matrix_vector_dot(x, y):\n",
        "    assert len(x.shape) == 2 # x is a NumPy matrix.\n",
        "    assert len(y.shape) == 1 # y is a NumPy vector.\n",
        "    assert x.shape[1] == y.shape[0] # The first dimension of x must be the same as the 0th dimension of y!\n",
        "    z = np.zeros(x.shape[0]) # This operation returns a vector of 0s with the same shape as y.\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            z[i] += x[i, j] * y[j]\n",
        "    return z"
      ],
      "metadata": {
        "id": "xHDRa8PnypSy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You could also reuse the code we wrote previously, which highlights \n",
        "# the relationship between a matrix-vector product and a vector product:\n",
        "\n",
        "def naive_matrix_vector_dot(x, y):\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        z[i] = naive_vector_dot(x[i, :], y)\n",
        "    return z"
      ],
      "metadata": {
        "id": "6oWQRXFfzGUa"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_matrix_dot(x, y):\n",
        "    assert len(x.shape) == 2 # x and y are NumPy matrices.\n",
        "    assert len(y.shape) == 2 # x and y are NumPy matrices.\n",
        "    assert x.shape[1] == y.shape[0] # The first dimension of x must be the same as the 0th dimension of y!\n",
        "    z = np.zeros((x.shape[0], y.shape[1])) # This operation returns a matrix of 0s with a specific shape.\n",
        "    for i in range(x.shape[0]): # Iterates over the rows of x . . .\n",
        "        for j in range(y.shape[1]): # . . . and over the columns of y.\n",
        "            row_x = x[i, :]\n",
        "            column_y = y[:, j]\n",
        "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
        "    return z"
      ],
      "metadata": {
        "id": "HUqDmtu0zPoG"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor reshaping\n",
        "### A third type of tensor operation that’s essential to understand is tensor reshaping. Although it wasn’t used in the Dense layers in our first neural network example, we used it when we preprocessed the digits data before feeding it into our model:"
      ],
      "metadata": {
        "id": "dHvIW88IqWwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "x = np.array([[0., 1.], [2., 3.], [4., 5.]])\n",
        "x"
      ],
      "metadata": {
        "id": "J8zDXl36zyXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecb2f3d-44fc-4d64-bedf-48315832531c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [2., 3.],\n",
              "       [4., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBER_FEEqtFP",
        "outputId": "f7f38ca3-276b-4863-9add-43fc57d65298"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping\n",
        "x = x.reshape((6, 1))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kd18YShq5He",
        "outputId": "4b5c0fde-9f48-4ad1-dd20-2971a2b8c5b8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [4.],\n",
              "       [5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((300, 20))\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT5V51OPq8OW",
        "outputId": "857979ed-c13b-4053-d579-2350acee368f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transpose with numpy\n",
        "x = np.transpose(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLg4ytA6rCyj",
        "outputId": "6b17aef8-c7a4-4ca6-e8a1-5d3068eef3f1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rPXfvekQrFpO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((300, 20))\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO0U0wkMrSiH",
        "outputId": "63a05db7-0c7a-4848-b197-9f032f90b905"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transpose with pandas\n",
        "x = x.T\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLKgwaXDrT3s",
        "outputId": "e4282a71-97be-4e65-c02f-f2dc0091a78f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geometric interpretation of tensor operations\n",
        "### Because the contents of the tensors manipulated by tensor operations can be interpreted as coordinates of points in some geometric space, all tensor operations have a geometric interpretation. For instance, let’s consider addition. We’ll start with the following vector:"
      ],
      "metadata": {
        "id": "IaCWo9jJrgGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = [0.5, 1]"
      ],
      "metadata": {
        "id": "UypnfMKnrXP3"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B = [1, 0.25]"
      ],
      "metadata": {
        "id": "2-EGYk99rr6C"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AB = [0.5,1,1,0.25]"
      ],
      "metadata": {
        "id": "pi7JaYJxtLod"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THE GRADIENT TAPE IN TENSORFLOW\n",
        "\n",
        "### The API through which you can leverage TensorFlow’s powerful automatic differentiation capabilities is the GradientTape. It’s a Python scope that will “record” the tensor operations that run inside it, in the form of a computation graph (sometimes called a “tape”). This graph can then be used to retrieve the gradient of any output with respect to any variable or set of variables (instances of the tf.Variable class). A tf.Variable is a specific kind of tensor meant to hold mutable state—for instance, the weights of a neural network are always tf.Variable instances."
      ],
      "metadata": {
        "id": "f_SnKab0r-xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "x = tf.Variable(0.) # Instantiate a scalar Variable with an initial value of 0.  \n",
        "with tf.GradientTape() as tape: # Open a GradientTape scope.\n",
        "    y = 2 * x + 3 # Inside the scope, apply some tensor operations to our variable.                    \n",
        "grad_of_y_wrt_x = tape.gradient(y, x) # Use the tape to retrieve the gradient of the output y with respect to our variable x."
      ],
      "metadata": {
        "id": "VYJ6NSbLs_N-"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The GradientTape works with tensor operations:\n",
        "x = tf.Variable(tf.random.uniform((2, 2)))\n",
        "with tf.GradientTape() as tape:\n",
        "    # Instantiate a Variable with shape (2, 2) and an initial value of all zeros.\n",
        "    y = 2 * x + 3 \n",
        "    # grad_of_y_wrt_x is a tensor of shape (2, 2) (like x) describing \n",
        "    # the curvature of y = 2 * a + 3 around x = [[0, 0], [0, 0]].\n",
        "    grad_of_y_wrt_x = tape.gradient(y, x)"
      ],
      "metadata": {
        "id": "3U60ikulsZVw"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It also works with lists of variables:\n",
        "\n",
        "W = tf.Variable(tf.random.uniform((2, 2)))\n",
        "b = tf.Variable(tf.zeros((2,)))\n",
        "x = tf.random.uniform((2, 2)) \n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.matmul(x, W) + b # matmul is how you say “dot product” in TensorFlow.\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n",
        "# grad_of_y_wrt_W_and_b is a list of two tensors with the same shapes as W and b, respectively."
      ],
      "metadata": {
        "id": "yapYsHLYstwR"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looking back at our first example\n",
        "###You’re nearing the end of this chapter, and you should now have a general understanding of what’s going on behind the scenes in a neural network. What was a magical black box at the start of the chapter has turned into a clearer picture, as illustrated in figure 2.26: the model, composed of layers that are chained together, maps the input data to predictions. The loss function then compares these predictions to the targets, producing a loss value: a measure of how well the model’s predictions match what was expected. The optimizer uses this loss value to update the model’s weights."
      ],
      "metadata": {
        "id": "ZEkKNT6ZvXz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255 \n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "XZ_ONbKVuJTy"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([ layers.Dense(512, activation=\"relu\"), \n",
        "                          layers.Dense(10, activation=\"softmax\")])"
      ],
      "metadata": {
        "id": "kKEkhAh0vk9n"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This was the model-compilation step:\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "86dBqg49vp-I"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this was the training loop:\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-xePZVhvx8e",
        "outputId": "75936491-3789-4795-bfe2-9359ed328cb3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 7s 13ms/step - loss: 0.2516 - accuracy: 0.9263\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1030 - accuracy: 0.9695\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0671 - accuracy: 0.9797\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0488 - accuracy: 0.9849\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0364 - accuracy: 0.9889\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff733927b50>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "  \n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        " \n",
        "        w_shape = (input_size, output_size)\n",
        "        # Create a matrix, W, of shape (input_size, output_size), initialized with random values.\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value)\n",
        "  \n",
        "        b_shape = (output_size)                                           \n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value)\n",
        "        # Create a vector, b, of shape (output_size,), initialized with zeros.\n",
        "  \n",
        "    def __call__(self, inputs): # Apply the forward pass.\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "  \n",
        "    @property\n",
        "    def weights(self): # Convenience method for retrieving the layer’s weights\n",
        "        return [self.W, self.b]"
      ],
      "metadata": {
        "id": "ImA-HZEKv5Qd"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "  \n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "           x = layer(x)\n",
        "        return x\n",
        "  \n",
        "    @property \n",
        "    def weights(self):\n",
        "       weights = []\n",
        "       for layer in self.layers:\n",
        "           weights += layer.weights\n",
        "       return weights"
      ],
      "metadata": {
        "id": "GwG2Yvp6wo3w"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)]) \n",
        "assert len(model.weights) == 4 "
      ],
      "metadata": {
        "id": "9Je86tZtxf3y"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A BATCH GENERATOR\n",
        "\n",
        "# Next, we need a way to iterate over the MNIST data in mini-batches. This is easy:\n",
        "\n",
        "import math\n",
        "  \n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        " \n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ],
      "metadata": {
        "id": "au-hKRojxqn-"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)                                   \n",
        "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            labels_batch, predictions)                                      \n",
        "        average_loss = tf.reduce_mean(per_sample_losses) \n",
        "        # Run the “forward pass” (compute the model’s predictions under a GradientTape scope).\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    \"\"\"Compute the gradient of the loss with regard to the weights. \n",
        "    The output gradients is a list where each entry corresponds \n",
        "    to a weight from the model.weights list.\"\"\"\n",
        "    update_weights(gradients, model.weights)\n",
        "    # Update the weights using the gradients (we will define this function shortly).\n",
        "    return average_loss"
      ],
      "metadata": {
        "id": "_2FUqTK7xvqm"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3 \n",
        "  \n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign_sub(g * learning_rate)\n",
        "        # assign_sub is the equivalent of -= for TensorFlow variables."
      ],
      "metadata": {
        "id": "e17HWTPXyRxS"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "  \n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "  \n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ],
      "metadata": {
        "id": "k7_YcRn8ydJr"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The full training loop\n",
        "### An epoch of training simply consists of repeating the training step for each batch in the training data, and the full training loop is simply the repetition of one epoch:"
      ],
      "metadata": {
        "id": "8o-6pz7Vym2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"Epoch {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ],
      "metadata": {
        "id": "46d1eA_tyhta"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "  \n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255  \n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255 \n",
        "  \n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKWjVMXjyqOi",
        "outputId": "30596d3c-7083-4702-83b3-9f159e980a86"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "loss at batch 0: 5.61\n",
            "loss at batch 100: 2.22\n",
            "loss at batch 200: 2.20\n",
            "loss at batch 300: 2.10\n",
            "loss at batch 400: 2.22\n",
            "Epoch 1\n",
            "loss at batch 0: 1.92\n",
            "loss at batch 100: 1.87\n",
            "loss at batch 200: 1.82\n",
            "loss at batch 300: 1.73\n",
            "loss at batch 400: 1.83\n",
            "Epoch 2\n",
            "loss at batch 0: 1.60\n",
            "loss at batch 100: 1.57\n",
            "loss at batch 200: 1.49\n",
            "loss at batch 300: 1.44\n",
            "loss at batch 400: 1.51\n",
            "Epoch 3\n",
            "loss at batch 0: 1.34\n",
            "loss at batch 100: 1.34\n",
            "loss at batch 200: 1.23\n",
            "loss at batch 300: 1.22\n",
            "loss at batch 400: 1.28\n",
            "Epoch 4\n",
            "loss at batch 0: 1.14\n",
            "loss at batch 100: 1.15\n",
            "loss at batch 200: 1.03\n",
            "loss at batch 300: 1.05\n",
            "loss at batch 400: 1.11\n",
            "Epoch 5\n",
            "loss at batch 0: 0.99\n",
            "loss at batch 100: 1.01\n",
            "loss at batch 200: 0.89\n",
            "loss at batch 300: 0.93\n",
            "loss at batch 400: 0.99\n",
            "Epoch 6\n",
            "loss at batch 0: 0.88\n",
            "loss at batch 100: 0.91\n",
            "loss at batch 200: 0.79\n",
            "loss at batch 300: 0.84\n",
            "loss at batch 400: 0.90\n",
            "Epoch 7\n",
            "loss at batch 0: 0.80\n",
            "loss at batch 100: 0.82\n",
            "loss at batch 200: 0.71\n",
            "loss at batch 300: 0.76\n",
            "loss at batch 400: 0.83\n",
            "Epoch 8\n",
            "loss at batch 0: 0.73\n",
            "loss at batch 100: 0.75\n",
            "loss at batch 200: 0.65\n",
            "loss at batch 300: 0.71\n",
            "loss at batch 400: 0.78\n",
            "Epoch 9\n",
            "loss at batch 0: 0.68\n",
            "loss at batch 100: 0.70\n",
            "loss at batch 200: 0.60\n",
            "loss at batch 300: 0.66\n",
            "loss at batch 400: 0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "predictions = model(test_images)\n",
        "predictions = predictions.numpy() # Calling .numpy() on a TensorFlow tensor converts it to a NumPy tensor.\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"accuracy: {matches.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRpkVK32ysoh",
        "outputId": "5b297c64-41f9-45d6-f7db-265dac233d43"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vfTVP5aky5IC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}